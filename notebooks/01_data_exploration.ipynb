{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EcoPredict Data Exploration\n",
    "\n",
    "This notebook explores the ecological data used in the EcoPredict system, including climate, land use, and species occurrence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for exploration\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Maharashtra bounds\n",
    "lat_range = (15.6, 22.0)\n",
    "lon_range = (72.6, 80.9)\n",
    "\n",
    "data = {\n",
    "    # Location\n",
    "    'latitude': np.random.uniform(lat_range[0], lat_range[1], n_samples),\n",
    "    'longitude': np.random.uniform(lon_range[0], lon_range[1], n_samples),\n",
    "    \n",
    "    # Climate variables\n",
    "    'temperature': np.random.normal(25, 5, n_samples),\n",
    "    'precipitation': np.random.exponential(2, n_samples),\n",
    "    'humidity': np.random.normal(60, 15, n_samples),\n",
    "    'wind_speed': np.random.exponential(3, n_samples),\n",
    "    \n",
    "    # Land use\n",
    "    'forest_cover': np.random.uniform(0, 1, n_samples),\n",
    "    'agricultural_area': np.random.uniform(0, 1, n_samples),\n",
    "    'urban_area': np.random.uniform(0, 1, n_samples),\n",
    "    'water_bodies': np.random.uniform(0, 0.3, n_samples),\n",
    "    \n",
    "    # Biodiversity\n",
    "    'species_count': np.random.poisson(15, n_samples),\n",
    "    'endemic_species': np.random.poisson(2, n_samples),\n",
    "    'threatened_species': np.random.poisson(1, n_samples),\n",
    "    \n",
    "    # Other factors\n",
    "    'elevation': np.random.normal(500, 300, n_samples),\n",
    "    'population_density': np.random.exponential(100, n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate risk score based on features\n",
    "risk_score = (\n",
    "    0.3 * (1 - df['forest_cover']) +\n",
    "    0.2 * df['urban_area'] +\n",
    "    0.15 * np.abs(df['temperature'] - 25) / 10 +\n",
    "    0.1 * (1 / (df['species_count'] + 1)) +\n",
    "    0.1 * df['population_density'] / 1000 +\n",
    "    0.15 * np.random.normal(0, 0.1, n_samples)\n",
    ")\n",
    "\n",
    "df['risk_score'] = np.clip(risk_score, 0, 1)\n",
    "df['risk_category'] = pd.cut(df['risk_score'], bins=[0, 0.3, 0.6, 1.0], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geographic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic scatter plot\n",
    "fig = px.scatter_mapbox(\n",
    "    df, \n",
    "    lat='latitude', \n",
    "    lon='longitude',\n",
    "    color='risk_score',\n",
    "    size='species_count',\n",
    "    hover_data=['temperature', 'forest_cover', 'risk_category'],\n",
    "    color_continuous_scale='RdYlGn_r',\n",
    "    mapbox_style='open-street-map',\n",
    "    title='Geographic Distribution of Ecological Risk',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox=dict(\n",
    "        center=dict(lat=df['latitude'].mean(), lon=df['longitude'].mean()),\n",
    "        zoom=6\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk category distribution by location\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Latitude distribution by risk\n",
    "for category in df['risk_category'].unique():\n",
    "    subset = df[df['risk_category'] == category]\n",
    "    axes[0].hist(subset['latitude'], alpha=0.7, label=category, bins=20)\n",
    "axes[0].set_xlabel('Latitude')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Risk Distribution by Latitude')\n",
    "axes[0].legend()\n",
    "\n",
    "# Longitude distribution by risk\n",
    "for category in df['risk_category'].unique():\n",
    "    subset = df[df['risk_category'] == category]\n",
    "    axes[1].hist(subset['longitude'], alpha=0.7, label=category, bins=20)\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Risk Distribution by Longitude')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Climate Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate variables distribution\n",
    "climate_vars = ['temperature', 'precipitation', 'humidity', 'wind_speed']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(climate_vars):\n",
    "    axes[i].hist(df[var], bins=30, alpha=0.7, color=sns.color_palette()[i])\n",
    "    axes[i].set_title(f'{var.title()} Distribution')\n",
    "    axes[i].set_xlabel(var.title())\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate vs Risk relationship\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Temperature vs Risk', 'Precipitation vs Risk', \n",
    "                   'Humidity vs Risk', 'Wind Speed vs Risk']\n",
    ")\n",
    "\n",
    "climate_vars = ['temperature', 'precipitation', 'humidity', 'wind_speed']\n",
    "positions = [(1,1), (1,2), (2,1), (2,2)]\n",
    "\n",
    "for var, (row, col) in zip(climate_vars, positions):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[var], \n",
    "            y=df['risk_score'],\n",
    "            mode='markers',\n",
    "            name=var,\n",
    "            opacity=0.6\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Climate Variables vs Ecological Risk\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Land Use Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Land use composition\n",
    "land_use_vars = ['forest_cover', 'agricultural_area', 'urban_area', 'water_bodies']\n",
    "\n",
    "# Average land use composition\n",
    "avg_composition = df[land_use_vars].mean()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=land_use_vars,\n",
    "    values=avg_composition.values,\n",
    "    hole=0.3\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Average Land Use Composition\",\n",
    "    annotations=[dict(text='Land Use', x=0.5, y=0.5, font_size=20, showarrow=False)]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Land use vs risk correlation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(land_use_vars):\n",
    "    axes[i].scatter(df[var], df['risk_score'], alpha=0.6, color=sns.color_palette()[i])\n",
    "    axes[i].set_xlabel(f'{var.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_ylabel('Risk Score')\n",
    "    axes[i].set_title(f'{var.replace(\"_\", \" \").title()} vs Risk Score')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df[var], df['risk_score'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(df[var], p(df[var]), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Biodiversity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species distribution\n",
    "biodiversity_vars = ['species_count', 'endemic_species', 'threatened_species']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(biodiversity_vars):\n",
    "    axes[i].hist(df[var], bins=20, alpha=0.7, color=sns.color_palette()[i])\n",
    "    axes[i].set_title(f'{var.replace(\"_\", \" \").title()} Distribution')\n",
    "    axes[i].set_xlabel(var.replace(\"_\", \" \").title())\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biodiversity hotspots\n",
    "df['biodiversity_index'] = (\n",
    "    df['species_count'] * 0.5 + \n",
    "    df['endemic_species'] * 0.3 + \n",
    "    df['threatened_species'] * 0.2\n",
    ")\n",
    "\n",
    "# Top 10% biodiversity hotspots\n",
    "hotspot_threshold = df['biodiversity_index'].quantile(0.9)\n",
    "hotspots = df[df['biodiversity_index'] >= hotspot_threshold]\n",
    "\n",
    "print(f\"Identified {len(hotspots)} biodiversity hotspots (top 10%)\")\n",
    "print(f\"Average risk score in hotspots: {hotspots['risk_score'].mean():.3f}\")\n",
    "print(f\"Average risk score overall: {df['risk_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biodiversity vs Risk\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='species_count', \n",
    "    y='risk_score',\n",
    "    color='risk_category',\n",
    "    size='biodiversity_index',\n",
    "    hover_data=['endemic_species', 'threatened_species'],\n",
    "    title='Species Count vs Ecological Risk',\n",
    "    color_discrete_map={'Low': 'green', 'Medium': 'orange', 'High': 'red'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    mask=mask,\n",
    "    annot=True, \n",
    "    cmap='RdBu_r', \n",
    "    center=0,\n",
    "    square=True,\n",
    "    fmt='.2f'\n",
    ")\n",
    "plt.title('Variable Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk score correlations\n",
    "risk_correlations = correlation_matrix['risk_score'].abs().sort_values(ascending=False)\n",
    "risk_correlations = risk_correlations[risk_correlations.index != 'risk_score']\n",
    "\n",
    "print(\"Variables most correlated with risk score:\")\n",
    "print(risk_correlations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top correlations with risk\n",
    "top_correlations = risk_correlations.head(8)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(len(top_correlations)), top_correlations.values)\n",
    "plt.xticks(range(len(top_correlations)), top_correlations.index, rotation=45, ha='right')\n",
    "plt.ylabel('Absolute Correlation with Risk Score')\n",
    "plt.title('Top Variables Correlated with Ecological Risk')\n",
    "\n",
    "# Color bars based on correlation strength\n",
    "for i, bar in enumerate(bars):\n",
    "    if top_correlations.values[i] > 0.5:\n",
    "        bar.set_color('red')\n",
    "    elif top_correlations.values[i] > 0.3:\n",
    "        bar.set_color('orange')\n",
    "    else:\n",
    "        bar.set_color('green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Risk Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk category distribution\n",
    "risk_counts = df['risk_category'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "axes[0].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', \n",
    "           colors=['green', 'orange', 'red'])\n",
    "axes[0].set_title('Risk Category Distribution')\n",
    "\n",
    "# Bar chart\n",
    "bars = axes[1].bar(risk_counts.index, risk_counts.values, \n",
    "                  color=['green', 'orange', 'red'])\n",
    "axes[1].set_title('Risk Category Counts')\n",
    "axes[1].set_ylabel('Number of Locations')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk score distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['risk_score'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(df['risk_score'].mean(), color='red', linestyle='--', \n",
    "           label=f'Mean: {df[\"risk_score\"].mean():.3f}')\n",
    "plt.axvline(df['risk_score'].median(), color='green', linestyle='--', \n",
    "           label=f'Median: {df[\"risk_score\"].median():.3f}')\n",
    "plt.xlabel('Risk Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Risk Score Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df.boxplot(column='risk_score', by='risk_category', ax=plt.gca())\n",
    "plt.title('Risk Score by Category')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics by Risk Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by risk category\n",
    "summary_stats = df.groupby('risk_category').agg({\n",
    "    'temperature': ['mean', 'std'],\n",
    "    'precipitation': ['mean', 'std'],\n",
    "    'forest_cover': ['mean', 'std'],\n",
    "    'species_count': ['mean', 'std'],\n",
    "    'urban_area': ['mean', 'std'],\n",
    "    'population_density': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"Summary Statistics by Risk Category:\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights\n",
    "print(\"=== KEY INSIGHTS ===\")\n",
    "print(f\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Total locations analyzed: {len(df):,}\")\n",
    "print(f\"   - Geographic coverage: {df['latitude'].min():.2f}°N to {df['latitude'].max():.2f}°N\")\n",
    "print(f\"   - Longitude range: {df['longitude'].min():.2f}°E to {df['longitude'].max():.2f}°E\")\n",
    "\n",
    "print(f\"\\n2. Risk Distribution:\")\n",
    "for category in ['Low', 'Medium', 'High']:\n",
    "    count = len(df[df['risk_category'] == category])\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   - {category} risk: {count:,} locations ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n3. Environmental Factors:\")\n",
    "print(f\"   - Average temperature: {df['temperature'].mean():.1f}°C (±{df['temperature'].std():.1f})\")\n",
    "print(f\"   - Average precipitation: {df['precipitation'].mean():.1f}mm (±{df['precipitation'].std():.1f})\")\n",
    "print(f\"   - Average forest cover: {df['forest_cover'].mean():.1%} (±{df['forest_cover'].std():.1%})\")\n",
    "\n",
    "print(f\"\\n4. Biodiversity:\")\n",
    "print(f\"   - Average species count: {df['species_count'].mean():.1f} (±{df['species_count'].std():.1f})\")\n",
    "print(f\"   - Total biodiversity hotspots identified: {len(hotspots)}\")\n",
    "print(f\"   - Average risk in hotspots: {hotspots['risk_score'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\n5. Strongest Risk Correlations:\")\n",
    "for var, corr in risk_correlations.head(3).items():\n",
    "    print(f\"   - {var.replace('_', ' ').title()}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "print(f\"\\n1. Completeness:\")\n",
    "print(f\"   - Total records: {len(df):,}\")\n",
    "print(f\"   - Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"   - Completeness rate: {(1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n2. Coordinate Validity:\")\n",
    "valid_lat = ((df['latitude'] >= -90) & (df['latitude'] <= 90)).sum()\n",
    "valid_lon = ((df['longitude'] >= -180) & (df['longitude'] <= 180)).sum()\n",
    "print(f\"   - Valid latitudes: {valid_lat}/{len(df)} ({valid_lat/len(df)*100:.1f}%)\")\n",
    "print(f\"   - Valid longitudes: {valid_lon}/{len(df)} ({valid_lon/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n3. Value Ranges:\")\n",
    "print(f\"   - Temperature range: {df['temperature'].min():.1f}°C to {df['temperature'].max():.1f}°C\")\n",
    "print(f\"   - Humidity range: {df['humidity'].min():.1f}% to {df['humidity'].max():.1f}%\")\n",
    "print(f\"   - Forest cover range: {df['forest_cover'].min():.1%} to {df['forest_cover'].max():.1%}\")\n",
    "\n",
    "print(f\"\\n4. Duplicates:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"   - Duplicate records: {duplicates} ({duplicates/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n✅ Data quality appears good for analysis and modeling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}